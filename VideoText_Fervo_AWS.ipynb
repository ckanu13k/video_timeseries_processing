{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the solution to Fervo Energy Interview video timeseries problem"
      ],
      "metadata": {
        "id": "-v94uQeK9ip8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UjgbN7QP9czy"
      },
      "outputs": [],
      "source": [
        "#!sudo apt -q install tesseract-ocr\n",
        "!pip -q install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import cv2\n",
        "import os\n",
        "import pytesseract\n",
        "from datetime import datetime\n",
        "import argparse\n",
        "import base64\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "import time\n",
        "import boto3\n",
        "import struct\n",
        "import pickle\n",
        "import json\n",
        "import botocore"
      ],
      "metadata": {
        "id": "yV1ZiwdNPnvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_name        = \"FervoEnergyVideo-VideoProcessing-Nv5REvJ0kicr\"             # Name of the Lambda function to invoke\n",
        "results_bucket     = \"video-results-obinnak\"                    # Bucket to use\n",
        "results_folder    = \"cpu_df\"  # Subfolder to place the calculation results\n",
        "concurrent_lambdas = 100\n",
        "\n",
        "source_bucket   = 'obinnak-public'    # S3 bucket name with input data\n",
        "source_folder   = 'data'         # Folder path, sometimes referred to as the prefix\n",
        "source_filename = 'Test_Video.mp4' # Filename\n",
        "is_gpu          = 'False'"
      ],
      "metadata": {
        "id": "LOm89m86yPXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get S3 object\n",
        "# Get the file stream\n",
        "s3 = boto3.resource('s3')\n",
        "data_obj = s3.Object(source_bucket, f\"{source_folder}/{source_filename}\")\n",
        "\n",
        "# Define some needed variables based off the above parameters\n",
        "start_time = time.time()\n",
        "\n",
        "results_file_list = [] # Lets keep track of the output file names, so we can grab them later\n",
        "\n",
        "lambda_client = boto3.client('lambda')\n",
        "\n",
        "# Build the message for the Lambda to find the video file\n",
        "payload = {\n",
        "    \"bucket_in\"          : source_bucket,\n",
        "    \"folder_in\"          : source_folder,\n",
        "    \"filename_in\"        : source_filename,\n",
        "    \"bucket_out\"         : results_bucket,\n",
        "    \"folder_out\"         : results_folder,\n",
        "    \"is_gpu\"             : is_gpu\n",
        "    }\n",
        "\n",
        "# Invoke the Lambda SegyBatchProcessMeanAmp\n",
        "response = lambda_client.invoke(FunctionName=lambda_name,\n",
        "                                InvocationType='Event',\n",
        "                                Payload=json.dumps(payload))\n",
        "\n",
        "results_file_list.append(f\"{results_folder}/{source_filename}.pkl\")\n",
        "\n",
        "print(\"Done!  Elapse time to gather send to and processing on Lambda: {:0.2f} seconds.  Now waiting for 80 seconds.\".format(time.time() - start_time))\n",
        "\n",
        "time.sleep(80)      # Waiting before carrying on next steps, to allow time for Lambda to finish."
      ],
      "metadata": {
        "id": "wICmal8AypUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3_client = boto3.client('s3')\n",
        "# Get file from S3, convert from Pickle format\n",
        "object = s3_client.get_object(Bucket=results_bucket, Key=results_file_list[x])\n",
        "\n",
        "serializedObject = object['Body'].read()\n",
        "results_bundle_temp = pickle.loads(serializedObject)"
      ],
      "metadata": {
        "id": "G1B_zPb30egX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}